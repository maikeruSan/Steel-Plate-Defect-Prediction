{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1321b33c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-15T07:27:45.928201Z",
     "iopub.status.busy": "2024-05-15T07:27:45.927569Z",
     "iopub.status.idle": "2024-05-15T07:28:03.827015Z",
     "shell.execute_reply": "2024-05-15T07:28:03.826090Z"
    },
    "papermill": {
     "duration": 17.907112,
     "end_time": "2024-05-15T07:28:03.829385",
     "exception": false,
     "start_time": "2024-05-15T07:27:45.922273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 07:27:55.817470: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-15 07:27:55.817590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-15 07:27:55.928741: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import polars as pl\n",
    "\n",
    "# Huggin Face \n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "from tokenizers import AddedToken\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "# scikit-learn\n",
    "from sklearn.metrics import (accuracy_score,cohen_kappa_score)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from typing import Tuple,List\n",
    "import gc\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da3abbc",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-15T07:28:03.838572Z",
     "iopub.status.busy": "2024-05-15T07:28:03.838042Z",
     "iopub.status.idle": "2024-05-15T07:28:17.030359Z",
     "shell.execute_reply": "2024-05-15T07:28:17.029235Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 13.199478,
     "end_time": "2024-05-15T07:28:17.032879",
     "exception": false,
     "start_time": "2024-05-15T07:28:03.833401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.6.1)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.1)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\r\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.1)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5caf4d7a",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-15T07:28:17.043181Z",
     "iopub.status.busy": "2024-05-15T07:28:17.042859Z",
     "iopub.status.idle": "2024-05-15T07:28:29.432638Z",
     "shell.execute_reply": "2024-05-15T07:28:29.431665Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 12.397425,
     "end_time": "2024-05-15T07:28:29.434952",
     "exception": false,
     "start_time": "2024-05-15T07:28:17.037527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[tune] in /opt/conda/lib/python3.10/site-packages (2.9.0)\r\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (8.1.7)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (3.13.1)\r\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (4.20.0)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (1.0.7)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (3.20.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (6.0.1)\r\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (1.3.1)\r\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (1.4.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (2.31.0)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (2.1.4)\r\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (2.6.2.2)\r\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (15.0.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (2024.2.0)\r\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from pyarrow>=6.0.1->ray[tune]) (1.26.4)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray[tune]) (23.2.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray[tune]) (2023.12.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray[tune]) (0.32.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray[tune]) (0.16.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray[tune]) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->ray[tune]) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->ray[tune]) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->ray[tune]) (2023.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray[tune]) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray[tune]) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray[tune]) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray[tune]) (2024.2.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->ray[tune]) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install ray[tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c203ed",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-15T07:28:29.445558Z",
     "iopub.status.busy": "2024-05-15T07:28:29.445281Z",
     "iopub.status.idle": "2024-05-15T07:28:45.857720Z",
     "shell.execute_reply": "2024-05-15T07:28:45.856657Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 16.420675,
     "end_time": "2024-05-15T07:28:45.860343",
     "exception": false,
     "start_time": "2024-05-15T07:28:29.439668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\r\n",
      "Collecting wandb\r\n",
      "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\r\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (4.2.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\r\n",
      "Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: wandb\r\n",
      "  Attempting uninstall: wandb\r\n",
      "    Found existing installation: wandb 0.16.6\r\n",
      "    Uninstalling wandb-0.16.6:\r\n",
      "      Successfully uninstalled wandb-0.16.6\r\n",
      "Successfully installed wandb-0.17.0\r\n"
     ]
    }
   ],
   "source": [
    "! pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96dad810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T07:28:45.873906Z",
     "iopub.status.busy": "2024-05-15T07:28:45.873592Z",
     "iopub.status.idle": "2024-05-15T07:28:45.883086Z",
     "shell.execute_reply": "2024-05-15T07:28:45.882178Z"
    },
    "papermill": {
     "duration": 0.018466,
     "end_time": "2024-05-15T07:28:45.885063",
     "exception": false,
     "start_time": "2024-05-15T07:28:45.866597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Tokenize(object):\n",
    "    def __init__(self, train, valid, tokenizer,max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def get_dataset(self, df):\n",
    "        ds = Dataset.from_dict({\n",
    "                'essay_id': [e for e in df['essay_id']],\n",
    "                'full_text': [ft for ft in df['full_text']],\n",
    "                'label': [s for s in df['label']],\n",
    "            })\n",
    "        return ds\n",
    "        \n",
    "    def tokenize_function(self, example):\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            example['full_text'], truncation=True, max_length=self.max_length,\n",
    "        )\n",
    "        return tokenized_inputs\n",
    "    \n",
    "    def __call__(self):\n",
    "        train_ds = self.get_dataset(self.train)\n",
    "        valid_ds = self.get_dataset(self.valid)\n",
    "        \n",
    "        tokenized_train = train_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        tokenized_valid = valid_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        \n",
    "        return tokenized_train, tokenized_valid, self.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ed3120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T07:28:45.897455Z",
     "iopub.status.busy": "2024-05-15T07:28:45.897177Z",
     "iopub.status.idle": "2024-05-15T07:28:45.909841Z",
     "shell.execute_reply": "2024-05-15T07:28:45.909076Z"
    },
    "papermill": {
     "duration": 0.021141,
     "end_time": "2024-05-15T07:28:45.911798",
     "exception": false,
     "start_time": "2024-05-15T07:28:45.890657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AESTraining:\n",
    "    \n",
    "    GOOGLE_BERT_BASE_CASED:str = \"google-bert/bert-base-cased\"\n",
    "    METRIC_NAME:str = \"qwk\"\n",
    "    NUMBER_OF_LABEL:int = 6\n",
    "    #MODEL_NAME:List[str]=[AESTraining.GOOGLE_BERT_BASE_CASED]\n",
    "        \n",
    "    def __init__(self,\n",
    "                 model_name:str,\n",
    "                 metric_name:str,\n",
    "                 number_of_label:int,\n",
    "                 learning_rate:float,\n",
    "                 token_max_len:int,\n",
    "                 batch_siz:int,\n",
    "                 weight_decay:float,\n",
    "                 train_epochs:int,\n",
    "                 optim:str\n",
    "                 ):\n",
    "        self.model_name = model_name\n",
    "        self.metric_name = model_name\n",
    "        self.token_max_len = token_max_len\n",
    "        self.batch_size = batch_siz\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_epochs = train_epochs\n",
    "        self.weight_decay = weight_decay\n",
    "        self.number_of_label = number_of_label\n",
    "        self.optim = optim\n",
    "        \n",
    "    #@staticmethod\n",
    "    #def read_train_csv(path:str=\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\")->pl.DataFrame:\n",
    "    #    return pl.read_csv(path)\n",
    "\n",
    " \n",
    "    @staticmethod\n",
    "    def df(path:str=\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\", \n",
    "              n_splits:int = 5, \n",
    "              label_col_name: str = \"score\",\n",
    "              random_state: int = 42) ->pd.DataFrame:\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        data = pd.read_csv(path)\n",
    "        data['label'] = data['score'].apply(lambda x: x-1)\n",
    "        for i, (_, val_index) in enumerate(skf.split(data, data[label_col_name])):\n",
    "            data.loc[val_index, \"fold\"] = i\n",
    "        return data\n",
    "        \n",
    "    def init_model(self):\n",
    "        config = AutoConfig.from_pretrained(self.model_name)\n",
    "        config.num_labels = self.number_of_label\n",
    "        return AutoModelForSequenceClassification.from_pretrained(self.model_name,num_labels=self.number_of_label)\n",
    "        \n",
    "    def tokenizer(self):\n",
    "        return AutoTokenizer.from_pretrained(self.model_name)\n",
    "        \n",
    "    \n",
    "    def default_training_Ars(self)->TrainingArguments:\n",
    "        return TrainingArguments(\n",
    "            \"/kaggle/working/output\",\n",
    "            evaluation_strategy = \"epoch\",\n",
    "            save_strategy = \"epoch\",\n",
    "            learning_rate= self.learning_rate ,#2e-5,\n",
    "            per_device_train_batch_size=self.batch_size,\n",
    "            per_device_eval_batch_size=self.batch_size,\n",
    "            num_train_epochs=self.train_epochs,\n",
    "            weight_decay= self.weight_decay, #0.01,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=self.metric_name,\n",
    "            push_to_hub=False,\n",
    "            optim=self.optim,\n",
    "        )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e09e2d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T07:28:45.924865Z",
     "iopub.status.busy": "2024-05-15T07:28:45.924560Z",
     "iopub.status.idle": "2024-05-15T07:28:46.772933Z",
     "shell.execute_reply": "2024-05-15T07:28:46.772089Z"
    },
    "papermill": {
     "duration": 0.857616,
     "end_time": "2024-05-15T07:28:46.775243",
     "exception": false,
     "start_time": "2024-05-15T07:28:45.917627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aes_training = AESTraining(model_name=\"/kaggle/input/huggingfacedebertav3variants/deberta-v3-base\",\n",
    "                           metric_name=AESTraining.METRIC_NAME,\n",
    "                           number_of_label=AESTraining.NUMBER_OF_LABEL,\n",
    "                           learning_rate=2e-5,\n",
    "                           token_max_len=1024,\n",
    "                           batch_siz=16,\n",
    "                           weight_decay=0.01,\n",
    "                           train_epochs=5,\n",
    "                           optim=\"adamw_torch\",\n",
    "                          )\n",
    "data : pd.DataFrame = aes_training.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc72b31f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T07:28:46.788832Z",
     "iopub.status.busy": "2024-05-15T07:28:46.788311Z",
     "iopub.status.idle": "2024-05-15T07:28:46.806113Z",
     "shell.execute_reply": "2024-05-15T07:28:46.805253Z"
    },
    "papermill": {
     "duration": 0.026706,
     "end_time": "2024-05-15T07:28:46.808024",
     "exception": false,
     "start_time": "2024-05-15T07:28:46.781318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    qwk = cohen_kappa_score(labels, predictions.argmax(-1), weights='quadratic')\n",
    "    results = {\n",
    "        'qwk': qwk\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 1, 10),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [4, 8, 16, 32]),\n",
    "        \"warmup_steps\": trial.suggest_int(\"warmup_steps\", 0, 500),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.3),\n",
    "        \"adam_beta1\": trial.suggest_float(\"adam_beta1\", 0.85, 0.95),\n",
    "        \"adam_beta2\": trial.suggest_float(\"adam_beta2\", 0.98, 0.999),\n",
    "        \"adam_epsilon\": trial.suggest_float(\"adam_epsilon\", 1e-8, 1e-6, log=True),\n",
    "        \"max_grad_norm\": trial.suggest_float(\"max_grad_norm\", 0.0, 1.0),\n",
    "        \"lr_scheduler_type\": trial.suggest_categorical(\"lr_scheduler_type\", [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"])\n",
    "    }\n",
    "\n",
    "def search_hp():\n",
    "    best_params_list = []\n",
    "    model_path = '/kaggle/input/huggingfacedebertav3variants/deberta-v3-base'\n",
    "    token_max_len = 1024\n",
    "    um_labels =6\n",
    "    output_dir = \"/kaggle/working/output\"\n",
    "    for fold in range(len(data['fold'].unique())):\n",
    "\n",
    "        train = data[data['fold'] != fold].copy()\n",
    "        valid = data[data['fold'] == fold].copy()\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "        tokenizer.add_tokens([AddedToken(\" \"*2, normalized=False)])\n",
    "        tokenize = Tokenize(train, valid, tokenizer,token_max_len)\n",
    "        tokenized_train, tokenized_valid, _ = tokenize()\n",
    "\n",
    "        # model = aes_training.init_model\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "        \n",
    "        def init_model():\n",
    "            return AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        \n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"/kaggle/working/output\",\n",
    "            evaluation_strategy = \"epoch\",\n",
    "            save_strategy = \"epoch\",\n",
    "            learning_rate= 2e-5,\n",
    "            per_device_train_batch_size=4,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs= 1,\n",
    "            weight_decay= 0.01,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=AESTraining.METRIC_NAME,\n",
    "            push_to_hub=False,\n",
    "            optim=\"adamw_torch\",\n",
    "        )\n",
    "        # training_args.output_dir = '/kaggle/working/output' \n",
    "        \n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=None,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_valid,\n",
    "            compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer,\n",
    "            model_init=init_model,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        best_run = trainer.hyperparameter_search(n_trials=40, direction=\"maximize\",backend=\"optuna\",hp_space=optuna_hp_space,)  \n",
    "        best_params_list.append(best_run.hyperparameters)\n",
    "        \n",
    "        # Save the hyperparameters for this fold\n",
    "        with open(os.path.join(output_dir, f\"best_params_fold_{fold}.json\"), \"w\") as f:\n",
    "            json.dump(best_run.hyperparameters, f, indent=4)\n",
    "        \n",
    "        \n",
    "        del trainer,tokenized_train, tokenized_valid\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    return best_runs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0568e356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T07:28:46.820375Z",
     "iopub.status.busy": "2024-05-15T07:28:46.820093Z",
     "iopub.status.idle": "2024-05-15T07:28:46.823862Z",
     "shell.execute_reply": "2024-05-15T07:28:46.823041Z"
    },
    "papermill": {
     "duration": 0.012185,
     "end_time": "2024-05-15T07:28:46.825838",
     "exception": false,
     "start_time": "2024-05-15T07:28:46.813653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search_hp()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 2663421,
     "sourceId": 4620664,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 66.117349,
   "end_time": "2024-05-15T07:28:49.384502",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-15T07:27:43.267153",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
