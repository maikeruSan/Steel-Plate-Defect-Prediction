{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ef5e4f",
   "metadata": {
    "_cell_guid": "6ef7cd1d-72cb-4be5-b19e-d6954107cb95",
    "_uuid": "877f0a84-80cc-4a10-9fa8-3477890a98d1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:51:27.255114Z",
     "iopub.status.busy": "2024-05-25T10:51:27.254801Z",
     "iopub.status.idle": "2024-05-25T10:51:49.826564Z",
     "shell.execute_reply": "2024-05-25T10:51:49.825612Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 22.579213,
     "end_time": "2024-05-25T10:51:49.828971",
     "exception": false,
     "start_time": "2024-05-25T10:51:27.249758",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25 10:51:39.661556: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-25 10:51:39.661651: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-25 10:51:39.817869: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple,List\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import polars as pl\n",
    "\n",
    "# Huggin Face \n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "from tokenizers import AddedToken\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "# scikit-learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "\n",
    "import wandb\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e680e7",
   "metadata": {
    "_cell_guid": "1fde9ea1-a907-404d-8f88-658f5e65b8c7",
    "_uuid": "0d55bd7c-8407-4087-a97f-3adeb31e7165",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:51:49.837960Z",
     "iopub.status.busy": "2024-05-25T10:51:49.837412Z",
     "iopub.status.idle": "2024-05-25T10:51:49.843256Z",
     "shell.execute_reply": "2024-05-25T10:51:49.842362Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012258,
     "end_time": "2024-05-25T10:51:49.845295",
     "exception": false,
     "start_time": "2024-05-25T10:51:49.833037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Initialize the Environment for Training =====\n",
      "===== Everything is Settled,WandB Run Name :1716634309 =====\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Initialize the Environment for Training =====\")\n",
    "WANDB_PROJECT_NAME = \"Kaggle_AES_HPS\"\n",
    "RUN_NAME =  int(time.time())\n",
    "#! pip install optuna\n",
    "#! pip install ray[tune]\n",
    "#! pip install wandb --upgrade\n",
    "os.environ[\"WANDB_PROJECT\"]=WANDB_PROJECT_NAME\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
    "print(f\"===== Everything is Settled,WandB Run Name :{RUN_NAME} =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb1d66d5",
   "metadata": {
    "_cell_guid": "7052cdac-a26e-43bb-8c4d-0700649338dc",
    "_uuid": "888a6f40-5f57-4708-98ef-d70a3eb80259",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:51:49.854172Z",
     "iopub.status.busy": "2024-05-25T10:51:49.853911Z",
     "iopub.status.idle": "2024-05-25T10:51:49.866872Z",
     "shell.execute_reply": "2024-05-25T10:51:49.866216Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01969,
     "end_time": "2024-05-25T10:51:49.868720",
     "exception": false,
     "start_time": "2024-05-25T10:51:49.849030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Tokenize(object):\n",
    "    def __init__(self, train, valid, tokenizer,max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def get_dataset(self, df):\n",
    "        ds = Dataset.from_dict({\n",
    "                'essay_id': [e for e in df['essay_id']],\n",
    "                'full_text': [ft for ft in df['full_text']],\n",
    "                'label': [s for s in df['label']],\n",
    "            })\n",
    "        return ds\n",
    "        \n",
    "    def tokenize_function(self, example):\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            example['full_text'], truncation=True, max_length=self.max_length,\n",
    "        )\n",
    "        return tokenized_inputs\n",
    "    \n",
    "    def __call__(self):\n",
    "        train_ds = self.get_dataset(self.train)\n",
    "        valid_ds = self.get_dataset(self.valid)\n",
    "        \n",
    "        tokenized_train = train_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        tokenized_valid = valid_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        \n",
    "        return tokenized_train, tokenized_valid, self.tokenizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fold_df(path:str=\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\", \n",
    "            n_splits:int = 5, \n",
    "            size:int = None,\n",
    "        label_col_name: str = \"score\",\n",
    "        random_state: int = 42) ->pd.DataFrame:\n",
    "    data = pd.read_csv(path)\n",
    "    data['label'] = data[label_col_name].apply(lambda x: x-1)\n",
    "        \n",
    "    if size :\n",
    "        data, _ = train_test_split(data, train_size=size, stratify=data[label_col_name], random_state=random_state)\n",
    "        data = data.reset_index(drop=True)\n",
    "        \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for i, (_, val_index) in enumerate(skf.split(data, data[label_col_name])):\n",
    "        data.loc[val_index, \"fold\"] = i\n",
    "    \n",
    "    return data\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    qwk = cohen_kappa_score(labels, predictions.argmax(-1), weights='quadratic')\n",
    "    results = {\n",
    "        'qwk': qwk\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd2fce1",
   "metadata": {
    "_cell_guid": "01e4a7e8-fb8d-443a-a905-228c2dd3a260",
    "_uuid": "e4a93f97-3c62-4f03-9434-fe436cebf35a",
    "execution": {
     "iopub.execute_input": "2024-05-25T10:51:49.877719Z",
     "iopub.status.busy": "2024-05-25T10:51:49.877408Z",
     "iopub.status.idle": "2024-05-25T10:51:49.886167Z",
     "shell.execute_reply": "2024-05-25T10:51:49.885470Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015286,
     "end_time": "2024-05-25T10:51:49.887924",
     "exception": false,
     "start_time": "2024-05-25T10:51:49.872638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sweep_configuration = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'eval_qwk',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 1e-6,\n",
    "            'max': 1e-4\n",
    "        },\n",
    "        'num_train_epochs': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 4,\n",
    "            'max': 20\n",
    "        },\n",
    "        'per_device_train_batch_size': {\n",
    "            'values': [1, 2, 3]\n",
    "        },\n",
    "        'per_device_eval_batch_size': {\n",
    "            'values': [1, 2, 3, 8]\n",
    "        },\n",
    "        'warmup_steps': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0,\n",
    "            'max': 500\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.0,\n",
    "            'max': 0.3\n",
    "        },\n",
    "        'adam_beta1': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 0.85,\n",
    "            'max': 0.95\n",
    "        },\n",
    "        'adam_beta2': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 0.98,\n",
    "            'max': 0.999\n",
    "        },\n",
    "        'adam_epsilon': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 1e-8,\n",
    "            'max': 1e-6\n",
    "        },\n",
    "        'max_grad_norm': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.0,\n",
    "            'max': 1.0\n",
    "        },\n",
    "        'lr_scheduler_type': {\n",
    "            'values': [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"]\n",
    "        }\n",
    "    },\n",
    "    'early_terminate': {\n",
    "        'type': 'hyperband',\n",
    "        'min_iter': 5,\n",
    "        'eta': 3\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "746a1005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:51:49.895892Z",
     "iopub.status.busy": "2024-05-25T10:51:49.895636Z",
     "iopub.status.idle": "2024-05-25T10:51:49.899232Z",
     "shell.execute_reply": "2024-05-25T10:51:49.898410Z"
    },
    "papermill": {
     "duration": 0.009695,
     "end_time": "2024-05-25T10:51:49.901136",
     "exception": false,
     "start_time": "2024-05-25T10:51:49.891441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "# k = 4\n",
    "# size = 1000\n",
    "agent_trail_count = 100\n",
    "# k_fold_df : pd.DataFrame = fold_df(size=size,n_splits=k)\n",
    "# range_k = range(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2501dd0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:51:49.909664Z",
     "iopub.status.busy": "2024-05-25T10:51:49.909409Z",
     "iopub.status.idle": "2024-05-25T10:51:49.924852Z",
     "shell.execute_reply": "2024-05-25T10:51:49.924079Z"
    },
    "papermill": {
     "duration": 0.021957,
     "end_time": "2024-05-25T10:51:49.926756",
     "exception": false,
     "start_time": "2024-05-25T10:51:49.904799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wandb_search_hp():\n",
    "    global i,hps_df,range_k\n",
    "    i+=1\n",
    "    print(f\"========= wandb_search_hp:{i} started =========\")\n",
    "    run = wandb.init()\n",
    "    qwk_scores = []\n",
    "    eval_loss = []\n",
    "    model_path = '/kaggle/input/huggingfacedebertav3variants/deberta-v3-base'\n",
    "    token_max_len = 1024\n",
    "    num_labels =6\n",
    "    output_dir = \"/kaggle/working/output\"\n",
    "    config = wandb.config\n",
    "    \n",
    "    k = 2\n",
    "    k_fold_df : pd.DataFrame = fold_df(size=2000,n_splits=k,random_state=RandomState().randint(0,4294967295)) # 2**32 - 1 = 4294967295\n",
    "    range_k = range(k-1)\n",
    "    \n",
    "    for fold in range_k:\n",
    "\n",
    "        train = k_fold_df[k_fold_df['fold'] != fold].copy()\n",
    "        valid = k_fold_df[k_fold_df['fold'] == fold].copy()\n",
    "        \n",
    "        print(f\"\"\"\n",
    "        ================================ \n",
    "        Hyper-Parameter #{i}  \n",
    "        Fold {fold} in Range {range_k} \n",
    "        Training Dataset Size : {len(train)}\n",
    "        Validation Dataset Size : {len(valid)}\n",
    "        ================================ \n",
    "        \"\"\")\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "        tokenizer.add_tokens([AddedToken(\" \"*2, normalized=False)])\n",
    "        tokenize = Tokenize(train, valid, tokenizer,token_max_len)\n",
    "        tokenized_train, tokenized_valid, _ = tokenize()\n",
    "\n",
    "        # model = aes_training.init_model\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "        \n",
    "        def init_model():\n",
    "            return AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        \n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"/kaggle/working/output\",\n",
    "            logging_dir=\"/kaggle/working/logs\",\n",
    "            evaluation_strategy = \"epoch\",\n",
    "            save_strategy = \"no\",  # Change to \"epoch\" if needed\n",
    "            learning_rate= config.learning_rate,\n",
    "            per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "            per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "            num_train_epochs= config.num_train_epochs,\n",
    "            weight_decay= config.weight_decay,\n",
    "            lr_scheduler_type=config.lr_scheduler_type,\n",
    "            max_grad_norm=config.max_grad_norm,\n",
    "            adam_epsilon=config.adam_epsilon,\n",
    "            adam_beta1=config.adam_beta1,\n",
    "            adam_beta2=config.adam_beta2,\n",
    "            warmup_steps=config.warmup_steps,\n",
    "            load_best_model_at_end=False,#True,\n",
    "            metric_for_best_model=\"qwk\",\n",
    "            push_to_hub=False,\n",
    "            optim=\"adamw_torch\",\n",
    "            report_to=\"wandb\",  # enable logging to W&B\n",
    "            run_name=f\"{RUN_NAME}_{fold}\",  # name of the W&B run (optional)\n",
    "            logging_steps=1,\n",
    "        )\n",
    "        # training_args.output_dir = '/kaggle/working/output' \n",
    "\n",
    "        trainer = Trainer(\n",
    "            model_init=init_model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_valid,\n",
    "            compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        \n",
    "        \n",
    "        # Evaluate the model on the validation set and get QWK score\n",
    "        metrics = trainer.evaluate(eval_dataset=tokenized_valid)\n",
    "        print(f\"\\n\\n ====metrics:{metrics}\\n\\n=====\")\n",
    "        qwk_scores.append(metrics['eval_qwk'])\n",
    "        eval_loss.append(metrics[\"eval_loss\"])\n",
    "       \n",
    "        \n",
    "        del trainer,tokenized_train, tokenized_valid\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    \n",
    "    eval_loss = np.mean(eval_loss)\n",
    "    eval_qwk = np.mean(qwk_scores)\n",
    "    wandb.log({\n",
    "                \"eval_loss\": eval_loss,\n",
    "               \"eval_qwk\": eval_qwk\n",
    "              }\n",
    "    )\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    ========= \n",
    "    Hyper-Parameter #{i}  Has Finished\n",
    "    Evaluation Loss:{eval_loss}\n",
    "    Evaluation QWK Score:{eval_qwk}\n",
    "    ========= \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "423d7df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:51:49.934896Z",
     "iopub.status.busy": "2024-05-25T10:51:49.934636Z",
     "iopub.status.idle": "2024-05-25T10:51:49.938206Z",
     "shell.execute_reply": "2024-05-25T10:51:49.937387Z"
    },
    "papermill": {
     "duration": 0.009854,
     "end_time": "2024-05-25T10:51:49.940091",
     "exception": false,
     "start_time": "2024-05-25T10:51:49.930237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wandb.login(key='81353c37543cb1d2f744d63a21a3648e98d4a9c1')\n",
    "#sweep_id = wandb.sweep(sweep=sweep_configuration, project=WANDB_PROJECT_NAME)\n",
    "#wandb.agent(sweep_id, wandb_search_hp, count=agent_trail_count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e353f1ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:51:49.948856Z",
     "iopub.status.busy": "2024-05-25T10:51:49.948307Z",
     "iopub.status.idle": "2024-05-25T10:51:49.952501Z",
     "shell.execute_reply": "2024-05-25T10:51:49.951715Z"
    },
    "papermill": {
     "duration": 0.010603,
     "end_time": "2024-05-25T10:51:49.954471",
     "exception": false,
     "start_time": "2024-05-25T10:51:49.943868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 2663421,
     "sourceId": 4620664,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28.350975,
   "end_time": "2024-05-25T10:51:52.598988",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-25T10:51:24.248013",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
