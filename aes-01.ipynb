{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9704be74",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-16T10:02:38.688978Z",
     "iopub.status.busy": "2024-05-16T10:02:38.688306Z",
     "iopub.status.idle": "2024-05-16T10:02:57.914030Z",
     "shell.execute_reply": "2024-05-16T10:02:57.913262Z"
    },
    "papermill": {
     "duration": 19.23309,
     "end_time": "2024-05-16T10:02:57.916199",
     "exception": false,
     "start_time": "2024-05-16T10:02:38.683109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 10:02:48.995495: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-16 10:02:48.995593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-16 10:02:49.124203: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import polars as pl\n",
    "\n",
    "# Huggin Face \n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "from tokenizers import AddedToken\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "# scikit-learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "\n",
    "from typing import Tuple,List\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "823f9c0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:02:57.924451Z",
     "iopub.status.busy": "2024-05-16T10:02:57.924181Z",
     "iopub.status.idle": "2024-05-16T10:03:39.010520Z",
     "shell.execute_reply": "2024-05-16T10:03:39.009136Z"
    },
    "papermill": {
     "duration": 41.09287,
     "end_time": "2024-05-16T10:03:39.012768",
     "exception": false,
     "start_time": "2024-05-16T10:02:57.919898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Initialize the Environment for Training =====\n",
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.6.1)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.1)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\r\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.1)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\r\n",
      "Requirement already satisfied: ray[tune] in /opt/conda/lib/python3.10/site-packages (2.9.0)\r\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (8.1.7)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (3.13.1)\r\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (4.20.0)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (1.0.7)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (3.20.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (6.0.1)\r\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (1.3.1)\r\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (1.4.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (2.31.0)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (2.1.4)\r\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (2.6.2.2)\r\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (15.0.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from ray[tune]) (2024.2.0)\r\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from pyarrow>=6.0.1->ray[tune]) (1.26.4)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray[tune]) (23.2.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray[tune]) (2023.12.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray[tune]) (0.32.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray[tune]) (0.16.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray[tune]) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->ray[tune]) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->ray[tune]) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->ray[tune]) (2023.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray[tune]) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray[tune]) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray[tune]) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray[tune]) (2024.2.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->ray[tune]) (1.16.0)\r\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\r\n",
      "Collecting wandb\r\n",
      "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\r\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (4.2.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\r\n",
      "Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: wandb\r\n",
      "  Attempting uninstall: wandb\r\n",
      "    Found existing installation: wandb 0.16.6\r\n",
      "    Uninstalling wandb-0.16.6:\r\n",
      "      Successfully uninstalled wandb-0.16.6\r\n",
      "Successfully installed wandb-0.17.0\r\n",
      "===== Everything is Settled =====\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Initialize the Environment for Training =====\")\n",
    "! pip install optuna\n",
    "! pip install ray[tune]\n",
    "! pip install wandb --upgrade\n",
    "os.environ[\"WANDB_PROJECT\"]=\"Kaggle_AES\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "print(\"===== Everything is Settled =====\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4c5792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:03:39.026202Z",
     "iopub.status.busy": "2024-05-16T10:03:39.025570Z",
     "iopub.status.idle": "2024-05-16T10:03:39.035182Z",
     "shell.execute_reply": "2024-05-16T10:03:39.034314Z"
    },
    "papermill": {
     "duration": 0.01851,
     "end_time": "2024-05-16T10:03:39.037114",
     "exception": false,
     "start_time": "2024-05-16T10:03:39.018604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Tokenize(object):\n",
    "    def __init__(self, train, valid, tokenizer,max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def get_dataset(self, df):\n",
    "        ds = Dataset.from_dict({\n",
    "                'essay_id': [e for e in df['essay_id']],\n",
    "                'full_text': [ft for ft in df['full_text']],\n",
    "                'label': [s for s in df['label']],\n",
    "            })\n",
    "        return ds\n",
    "        \n",
    "    def tokenize_function(self, example):\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            example['full_text'], truncation=True, max_length=self.max_length,\n",
    "        )\n",
    "        return tokenized_inputs\n",
    "    \n",
    "    def __call__(self):\n",
    "        train_ds = self.get_dataset(self.train)\n",
    "        valid_ds = self.get_dataset(self.valid)\n",
    "        \n",
    "        tokenized_train = train_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        tokenized_valid = valid_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        \n",
    "        return tokenized_train, tokenized_valid, self.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31a64aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:03:39.049453Z",
     "iopub.status.busy": "2024-05-16T10:03:39.049207Z",
     "iopub.status.idle": "2024-05-16T10:03:39.852503Z",
     "shell.execute_reply": "2024-05-16T10:03:39.851706Z"
    },
    "papermill": {
     "duration": 0.81224,
     "end_time": "2024-05-16T10:03:39.854943",
     "exception": false,
     "start_time": "2024-05-16T10:03:39.042703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " def fold_df(path:str=\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\", \n",
    "        n_splits:int = 5, \n",
    "        size:int = None,\n",
    "        label_col_name: str = \"score\",\n",
    "        random_state: int = 42) ->pd.DataFrame:\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        data = pd.read_csv(path)\n",
    "        data['label'] = data[label_col_name].apply(lambda x: x-1)\n",
    "        \n",
    "        if size :\n",
    "            data, _ = train_test_split(data, train_size=size, stratify=data[label_col_name], random_state=random_state)\n",
    "            data = data.reset_index(drop=True)\n",
    "        \n",
    "        for i, (_, val_index) in enumerate(skf.split(data, data[label_col_name])):\n",
    "            data.loc[val_index, \"fold\"] = i\n",
    "        return data\n",
    "    \n",
    "data : pd.DataFrame = fold_df(size=1000)\n",
    "# data[['fold','label']].groupby(['fold','label',]).size().reset_index(name=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "586d265a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:03:39.868650Z",
     "iopub.status.busy": "2024-05-16T10:03:39.868369Z",
     "iopub.status.idle": "2024-05-16T10:03:39.887895Z",
     "shell.execute_reply": "2024-05-16T10:03:39.887164Z"
    },
    "papermill": {
     "duration": 0.028358,
     "end_time": "2024-05-16T10:03:39.889861",
     "exception": false,
     "start_time": "2024-05-16T10:03:39.861503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    qwk = cohen_kappa_score(labels, predictions.argmax(-1), weights='quadratic')\n",
    "    results = {\n",
    "        'qwk': qwk\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 1, 10),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [1,2,3]),\n",
    "        \"warmup_steps\": trial.suggest_int(\"warmup_steps\", 0, 500),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.3),\n",
    "        \"adam_beta1\": trial.suggest_float(\"adam_beta1\", 0.85, 0.95),\n",
    "        \"adam_beta2\": trial.suggest_float(\"adam_beta2\", 0.98, 0.999),\n",
    "        \"adam_epsilon\": trial.suggest_float(\"adam_epsilon\", 1e-8, 1e-6, log=True),\n",
    "        \"max_grad_norm\": trial.suggest_float(\"max_grad_norm\", 0.0, 1.0),\n",
    "        \"lr_scheduler_type\": trial.suggest_categorical(\"lr_scheduler_type\", [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"])\n",
    "    }\n",
    "\n",
    "def search_hp():\n",
    "    best_params_list = []\n",
    "    qwk_scores = []\n",
    "    model_path = '/kaggle/input/huggingfacedebertav3variants/deberta-v3-base'\n",
    "    token_max_len = 1024\n",
    "    num_labels =6\n",
    "    output_dir = \"/kaggle/working/output\"\n",
    "    optuna_n_trials = 10\n",
    "    for fold in range(len(data['fold'].unique())):\n",
    "\n",
    "        train = data[data['fold'] != fold].copy()\n",
    "        valid = data[data['fold'] == fold].copy()\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "        tokenizer.add_tokens([AddedToken(\" \"*2, normalized=False)])\n",
    "        tokenize = Tokenize(train, valid, tokenizer,token_max_len)\n",
    "        tokenized_train, tokenized_valid, _ = tokenize()\n",
    "\n",
    "        # model = aes_training.init_model\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "        \n",
    "        def init_model():\n",
    "            return AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        \n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"/kaggle/working/output\",\n",
    "            evaluation_strategy = \"epoch\",\n",
    "            save_strategy = \"no\",#\"epoch\",\n",
    "            learning_rate= 2e-5,\n",
    "            per_device_train_batch_size=4,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs= 1,\n",
    "            weight_decay= 0.01,\n",
    "            load_best_model_at_end=False,#True,\n",
    "            metric_for_best_model=\"qwk\",\n",
    "            push_to_hub=False,\n",
    "            optim=\"adamw_torch\",\n",
    "        )\n",
    "        # training_args.output_dir = '/kaggle/working/output' \n",
    "        \n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=None,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_valid,\n",
    "            compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer,\n",
    "            model_init=init_model,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        best_run = trainer.hyperparameter_search(n_trials=optuna_n_trials, direction=\"maximize\",backend=\"optuna\",hp_space=optuna_hp_space,)  \n",
    "        best_params_list.append(best_run.hyperparameters)\n",
    "        \n",
    "        # Evaluate the model on the validation set and get QWK score\n",
    "        metrics = trainer.evaluate(eval_dataset=tokenized_valid)\n",
    "        qwk_scores.append(metrics['eval_qwk'])\n",
    "        \n",
    "        with open(os.path.join(output_dir, f\"best_params_fold_{fold}.json\"), \"w\") as f:\n",
    "            json.dump(best_run.hyperparameters, f, indent=4)\n",
    "        \n",
    "        \n",
    "        del trainer,tokenized_train, tokenized_valid\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # Save the QWK scores\n",
    "    with open(os.path.join(output_dir, \"qwk_scores.json\"), \"w\") as f:\n",
    "        json.dump(qwk_scores, f, indent=4)\n",
    "        \n",
    "    return best_params_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba4ca56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:03:39.901837Z",
     "iopub.status.busy": "2024-05-16T10:03:39.901582Z",
     "iopub.status.idle": "2024-05-16T10:03:39.905082Z",
     "shell.execute_reply": "2024-05-16T10:03:39.904348Z"
    },
    "papermill": {
     "duration": 0.011548,
     "end_time": "2024-05-16T10:03:39.906857",
     "exception": false,
     "start_time": "2024-05-16T10:03:39.895309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hps = search_hp()\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e11635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:03:39.918811Z",
     "iopub.status.busy": "2024-05-16T10:03:39.918515Z",
     "iopub.status.idle": "2024-05-16T10:03:39.921999Z",
     "shell.execute_reply": "2024-05-16T10:03:39.921171Z"
    },
    "papermill": {
     "duration": 0.011732,
     "end_time": "2024-05-16T10:03:39.923962",
     "exception": false,
     "start_time": "2024-05-16T10:03:39.912230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! rm -rf ./output/runs/\n",
    "# ! du -h --max-depth=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9838c660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T10:03:39.936308Z",
     "iopub.status.busy": "2024-05-16T10:03:39.935706Z",
     "iopub.status.idle": "2024-05-16T10:03:39.939344Z",
     "shell.execute_reply": "2024-05-16T10:03:39.938491Z"
    },
    "papermill": {
     "duration": 0.011921,
     "end_time": "2024-05-16T10:03:39.941282",
     "exception": false,
     "start_time": "2024-05-16T10:03:39.929361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#with open(f\"/kaggle/working/output/best_params_fold_1.json\", 'r') as file:\n",
    "#    j = json.load(file)\n",
    "    \n",
    "    \n",
    "#print(j)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 2663421,
     "sourceId": 4620664,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 67.141645,
   "end_time": "2024-05-16T10:03:43.176136",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-16T10:02:36.034491",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
