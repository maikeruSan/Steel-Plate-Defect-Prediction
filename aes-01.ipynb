{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05eb25c3",
   "metadata": {
    "_cell_guid": "6ef7cd1d-72cb-4be5-b19e-d6954107cb95",
    "_uuid": "877f0a84-80cc-4a10-9fa8-3477890a98d1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-22T09:45:08.324196Z",
     "iopub.status.busy": "2024-05-22T09:45:08.323804Z",
     "iopub.status.idle": "2024-05-22T09:45:27.823149Z",
     "shell.execute_reply": "2024-05-22T09:45:27.822164Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 19.507966,
     "end_time": "2024-05-22T09:45:27.825563",
     "exception": false,
     "start_time": "2024-05-22T09:45:08.317597",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 09:45:18.624672: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-22 09:45:18.624786: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-22 09:45:18.725237: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import polars as pl\n",
    "\n",
    "# Huggin Face \n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "from tokenizers import AddedToken\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "# scikit-learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "\n",
    "from typing import Tuple,List\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba969c18",
   "metadata": {
    "_cell_guid": "1fde9ea1-a907-404d-8f88-658f5e65b8c7",
    "_uuid": "0d55bd7c-8407-4087-a97f-3adeb31e7165",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-22T09:45:27.835229Z",
     "iopub.status.busy": "2024-05-22T09:45:27.834613Z",
     "iopub.status.idle": "2024-05-22T09:45:27.840624Z",
     "shell.execute_reply": "2024-05-22T09:45:27.839771Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012991,
     "end_time": "2024-05-22T09:45:27.842928",
     "exception": false,
     "start_time": "2024-05-22T09:45:27.829937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Initialize the Environment for Training =====\n",
      "===== Everything is Settled,WandB Run Name :1716371127 =====\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Initialize the Environment for Training =====\")\n",
    "WANDB_PROJECT_NAME = \"Kaggle_AES_HPS\"\n",
    "RUN_NAME =  int(time.time())\n",
    "#! pip install optuna\n",
    "#! pip install ray[tune]\n",
    "#! pip install wandb --upgrade\n",
    "os.environ[\"WANDB_PROJECT\"]=WANDB_PROJECT_NAME\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
    "print(f\"===== Everything is Settled,WandB Run Name :{RUN_NAME} =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc08722a",
   "metadata": {
    "_cell_guid": "7052cdac-a26e-43bb-8c4d-0700649338dc",
    "_uuid": "888a6f40-5f57-4708-98ef-d70a3eb80259",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-22T09:45:27.852432Z",
     "iopub.status.busy": "2024-05-22T09:45:27.851927Z",
     "iopub.status.idle": "2024-05-22T09:45:27.864962Z",
     "shell.execute_reply": "2024-05-22T09:45:27.864189Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.019982,
     "end_time": "2024-05-22T09:45:27.866776",
     "exception": false,
     "start_time": "2024-05-22T09:45:27.846794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Tokenize(object):\n",
    "    def __init__(self, train, valid, tokenizer,max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def get_dataset(self, df):\n",
    "        ds = Dataset.from_dict({\n",
    "                'essay_id': [e for e in df['essay_id']],\n",
    "                'full_text': [ft for ft in df['full_text']],\n",
    "                'label': [s for s in df['label']],\n",
    "            })\n",
    "        return ds\n",
    "        \n",
    "    def tokenize_function(self, example):\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            example['full_text'], truncation=True, max_length=self.max_length,\n",
    "        )\n",
    "        return tokenized_inputs\n",
    "    \n",
    "    def __call__(self):\n",
    "        train_ds = self.get_dataset(self.train)\n",
    "        valid_ds = self.get_dataset(self.valid)\n",
    "        \n",
    "        tokenized_train = train_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        tokenized_valid = valid_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        \n",
    "        return tokenized_train, tokenized_valid, self.tokenizer\n",
    "\n",
    "\n",
    "def fold_df(path:str=\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\", \n",
    "        n_splits:int = 5, \n",
    "        size:int = None,\n",
    "        label_col_name: str = \"score\",\n",
    "        random_state: int = 42) ->pd.DataFrame:\n",
    "\n",
    "        data = pd.read_csv(path)\n",
    "        data['label'] = data[label_col_name].apply(lambda x: x-1)\n",
    "        \n",
    "        if size :\n",
    "            data, _ = train_test_split(data, train_size=size, stratify=data[label_col_name], random_state=random_state)\n",
    "            data = data.reset_index(drop=True)\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        for i, (_, val_index) in enumerate(skf.split(data, data[label_col_name])):\n",
    "            data.loc[val_index, \"fold\"] = i\n",
    "        return data\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    qwk = cohen_kappa_score(labels, predictions.argmax(-1), weights='quadratic')\n",
    "    results = {\n",
    "        'qwk': qwk\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f597bbb4",
   "metadata": {
    "_cell_guid": "deb9c5ef-5a5a-40c4-a4ae-2a678c232dff",
    "_uuid": "f3b76ae7-b6c9-4305-8df8-54361be170ca",
    "execution": {
     "iopub.execute_input": "2024-05-22T09:45:27.875647Z",
     "iopub.status.busy": "2024-05-22T09:45:27.875412Z",
     "iopub.status.idle": "2024-05-22T09:45:27.889499Z",
     "shell.execute_reply": "2024-05-22T09:45:27.888672Z"
    },
    "papermill": {
     "duration": 0.020568,
     "end_time": "2024-05-22T09:45:27.891363",
     "exception": false,
     "start_time": "2024-05-22T09:45:27.870795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_hp(data,\n",
    "              hp_space,\n",
    "              backend,\n",
    "              opti_n_trials,\n",
    "             run_name):\n",
    "    best_params_list = []\n",
    "    qwk_scores = []\n",
    "    model_path = '/kaggle/input/huggingfacedebertav3variants/deberta-v3-base'\n",
    "    token_max_len = 1024\n",
    "    num_labels =6\n",
    "    output_dir = \"/kaggle/working/output\"\n",
    "    # optuna_n_trials = 10\n",
    "    for fold in range(len(data['fold'].unique())):\n",
    "\n",
    "        train = data[data['fold'] != fold].copy()\n",
    "        valid = data[data['fold'] == fold].copy()\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "        tokenizer.add_tokens([AddedToken(\" \"*2, normalized=False)])\n",
    "        tokenize = Tokenize(train, valid, tokenizer,token_max_len)\n",
    "        tokenized_train, tokenized_valid, _ = tokenize()\n",
    "\n",
    "        # model = aes_training.init_model\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "        \n",
    "        def init_model():\n",
    "            return AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        \n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"/kaggle/working/output\",\n",
    "            evaluation_strategy = \"epoch\",\n",
    "            save_strategy = \"no\",#\"epoch\",\n",
    "            learning_rate= 2e-5,\n",
    "            per_device_train_batch_size=4,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs= 1,\n",
    "            weight_decay= 0.01,\n",
    "            load_best_model_at_end=False,#True,\n",
    "            metric_for_best_model=\"qwk\",\n",
    "            push_to_hub=False,\n",
    "            optim=\"adamw_torch\",\n",
    "            report_to=\"wandb\",  # enable logging to W&B\n",
    "            run_name=f\"{run_name}_{fold}\",  # name of the W&B run (optional)\n",
    "            logging_steps=1,\n",
    "        )\n",
    "        # training_args.output_dir = '/kaggle/working/output' \n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=None,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_valid,\n",
    "            compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer,\n",
    "            model_init=init_model,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        best_run = trainer.hyperparameter_search(n_trials=opti_n_trials,#optuna_n_trials, \n",
    "                                                 direction=\"maximize\",\n",
    "                                                 backend=backend, # \"optuna\",\n",
    "                                                 hp_space=hp_space,)  \n",
    "        best_params_list.append(best_run.hyperparameters)\n",
    "        \n",
    "        # Evaluate the model on the validation set and get QWK score\n",
    "        metrics = trainer.evaluate(eval_dataset=tokenized_valid)\n",
    "        qwk_scores.append(metrics['eval_qwk'])\n",
    "        \n",
    "        with open(os.path.join(output_dir, f\"best_params_fold_{fold}.json\"), \"w\") as f:\n",
    "            json.dump(best_run.hyperparameters, f, indent=4)\n",
    "        \n",
    "        \n",
    "        del trainer,tokenized_train, tokenized_valid\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # Save the QWK scores\n",
    "    with open(os.path.join(output_dir, \"qwk_scores.json\"), \"w\") as f:\n",
    "        json.dump(qwk_scores, f, indent=4)\n",
    "        \n",
    "    return best_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c695503",
   "metadata": {
    "_cell_guid": "01e4a7e8-fb8d-443a-a905-228c2dd3a260",
    "_uuid": "e4a93f97-3c62-4f03-9434-fe436cebf35a",
    "execution": {
     "iopub.execute_input": "2024-05-22T09:45:27.900768Z",
     "iopub.status.busy": "2024-05-22T09:45:27.899992Z",
     "iopub.status.idle": "2024-05-22T09:45:27.908231Z",
     "shell.execute_reply": "2024-05-22T09:45:27.907553Z"
    },
    "papermill": {
     "duration": 0.015228,
     "end_time": "2024-05-22T09:45:27.910349",
     "exception": false,
     "start_time": "2024-05-22T09:45:27.895121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sweep_configuration = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'eval_qwk',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 1e-6,\n",
    "            'max': 1e-4\n",
    "        },\n",
    "        'num_train_epochs': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 4,\n",
    "            'max': 20\n",
    "        },\n",
    "        'per_device_train_batch_size': {\n",
    "            'values': [1, 2, 3]\n",
    "        },\n",
    "        'per_device_eval_batch_size': {\n",
    "            'values': [1, 2, 3, 8]\n",
    "        },\n",
    "        'warmup_steps': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0,\n",
    "            'max': 500\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.0,\n",
    "            'max': 0.3\n",
    "        },\n",
    "        'adam_beta1': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 0.85,\n",
    "            'max': 0.95\n",
    "        },\n",
    "        'adam_beta2': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 0.98,\n",
    "            'max': 0.999\n",
    "        },\n",
    "        'adam_epsilon': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 1e-8,\n",
    "            'max': 1e-6\n",
    "        },\n",
    "        'max_grad_norm': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.0,\n",
    "            'max': 1.0\n",
    "        },\n",
    "        'lr_scheduler_type': {\n",
    "            'values': [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"]\n",
    "        }\n",
    "    },\n",
    "    'early_terminate': {\n",
    "        'type': 'hyperband',\n",
    "        'min_iter': 5,\n",
    "        'eta': 3\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98a56ef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T09:45:27.919238Z",
     "iopub.status.busy": "2024-05-22T09:45:27.918935Z",
     "iopub.status.idle": "2024-05-22T09:45:27.933325Z",
     "shell.execute_reply": "2024-05-22T09:45:27.932443Z"
    },
    "papermill": {
     "duration": 0.021036,
     "end_time": "2024-05-22T09:45:27.935216",
     "exception": false,
     "start_time": "2024-05-22T09:45:27.914180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wandb_search_hp():\n",
    "    global i,hps_df,range_k\n",
    "    i+=1\n",
    "    print(f\"========= wandb_search_hp:{i} started =========\")\n",
    "    run = wandb.init()\n",
    "    qwk_scores = []\n",
    "    eval_loss = []\n",
    "    model_path = '/kaggle/input/huggingfacedebertav3variants/deberta-v3-base'\n",
    "    token_max_len = 1024\n",
    "    num_labels =6\n",
    "    output_dir = \"/kaggle/working/output\"\n",
    "    config = wandb.config\n",
    "    \n",
    "    for fold in range_k:\n",
    "        \n",
    "        print(f\"========= wandb_search_hp:{i},fold{fold} =========\")\n",
    "\n",
    "        train = k_fold_df[k_fold_df['fold'] != fold].copy()\n",
    "        valid = k_fold_df[k_fold_df['fold'] == fold].copy()\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "        tokenizer.add_tokens([AddedToken(\" \"*2, normalized=False)])\n",
    "        tokenize = Tokenize(train, valid, tokenizer,token_max_len)\n",
    "        tokenized_train, tokenized_valid, _ = tokenize()\n",
    "\n",
    "        # model = aes_training.init_model\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "        \n",
    "        def init_model():\n",
    "            return AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        \n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"/kaggle/working/output\",\n",
    "            logging_dir=\"/kaggle/working/logs\",\n",
    "            evaluation_strategy = \"epoch\",\n",
    "            save_strategy = \"no\",  # Change to \"epoch\" if needed\n",
    "            learning_rate= config.learning_rate,\n",
    "            per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "            per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "            num_train_epochs= config.num_train_epochs,\n",
    "            weight_decay= config.weight_decay,\n",
    "            lr_scheduler_type=config.lr_scheduler_type,\n",
    "            max_grad_norm=config.max_grad_norm,\n",
    "            adam_epsilon=config.adam_epsilon,\n",
    "            adam_beta1=config.adam_beta1,\n",
    "            adam_beta2=config.adam_beta2,\n",
    "            warmup_steps=config.warmup_steps,\n",
    "            load_best_model_at_end=False,#True,\n",
    "            metric_for_best_model=\"qwk\",\n",
    "            push_to_hub=False,\n",
    "            optim=\"adamw_torch\",\n",
    "            report_to=\"wandb\",  # enable logging to W&B\n",
    "            run_name=f\"{RUN_NAME}_{fold}\",  # name of the W&B run (optional)\n",
    "            logging_steps=1,\n",
    "        )\n",
    "        # training_args.output_dir = '/kaggle/working/output' \n",
    "\n",
    "        trainer = Trainer(\n",
    "            model_init=init_model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_valid,\n",
    "            compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        \n",
    "        \n",
    "        # Evaluate the model on the validation set and get QWK score\n",
    "        metrics = trainer.evaluate(eval_dataset=tokenized_valid)\n",
    "        print(f\"\\n\\n ====metrics:{metrics}\\n\\n=====\")\n",
    "        qwk_scores.append(metrics['eval_qwk'])\n",
    "        eval_loss.append(metrics[\"eval_loss\"])\n",
    "       \n",
    "        \n",
    "        del trainer,tokenized_train, tokenized_valid\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    \n",
    "    eval_loss = np.mean(eval_loss)\n",
    "    eval_qwk = np.mean(qwk_scores)\n",
    "    wandb.log({\n",
    "                \"eval_loss\": eval_loss,\n",
    "               \"eval_qwk\": eval_qwk\n",
    "              }\n",
    "    )\n",
    "    print(f\"========= wandb_search_hp:{i} has finished ========= \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88bc1652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T09:45:27.944667Z",
     "iopub.status.busy": "2024-05-22T09:45:27.944019Z",
     "iopub.status.idle": "2024-05-22T09:45:28.935179Z",
     "shell.execute_reply": "2024-05-22T09:45:28.933920Z"
    },
    "papermill": {
     "duration": 0.998537,
     "end_time": "2024-05-22T09:45:28.937798",
     "exception": false,
     "start_time": "2024-05-22T09:45:27.939261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wandb.login()\n",
    "#sweep_id = wandb.sweep(sweep=sweep_configuration, project=WANDB_PROJECT_NAME)\n",
    "i = 0\n",
    "k = 5\n",
    "size = 500\n",
    "agent_trail_count = 1\n",
    "k_fold_df : pd.DataFrame = fold_df(size=size,n_splits=k)\n",
    "range_k = range(k)\n",
    "#wandb.agent(sweep_id, wandb_search_hp, count=agent_trail_count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd14ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T09:45:28.948825Z",
     "iopub.status.busy": "2024-05-22T09:45:28.947982Z",
     "iopub.status.idle": "2024-05-22T09:45:28.953169Z",
     "shell.execute_reply": "2024-05-22T09:45:28.952105Z"
    },
    "papermill": {
     "duration": 0.013176,
     "end_time": "2024-05-22T09:45:28.955675",
     "exception": false,
     "start_time": "2024-05-22T09:45:28.942499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dddbc436",
   "metadata": {
    "_cell_guid": "8e136bcf-ce20-4257-9ee0-0b1349194d88",
    "_uuid": "47d2db44-7fad-40dd-8047-9c3290e4632a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-22T09:45:28.966194Z",
     "iopub.status.busy": "2024-05-22T09:45:28.965854Z",
     "iopub.status.idle": "2024-05-22T09:45:31.052832Z",
     "shell.execute_reply": "2024-05-22T09:45:31.051787Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.095071,
     "end_time": "2024-05-22T09:45:31.055334",
     "exception": false,
     "start_time": "2024-05-22T09:45:28.960263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28K\t.\r\n"
     ]
    }
   ],
   "source": [
    "# Clean the old straining Stuffs\n",
    "! rm -rf /kaggle/working/output\n",
    "# Check the avaiable space of the working folder avoiding disk no space exception during out training\n",
    "! du -h --max-depth=1"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 2663421,
     "sourceId": 4620664,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.178181,
   "end_time": "2024-05-22T09:45:34.619795",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-22T09:45:05.441614",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
